# Twitter
Twitterに関するもの

import sysabcdefgimport cv2abcdefgimport numpy as npabcdefgimport tensorflow as tfabcdefgimport tensorflow.python.platformabcdefgimport osabcdefgimport globabcdefgimport scipyabcdefgfrom scipy import ioabcdefgimport timeabcdefgfrom tensorflow.contrib import learnabcdefgimport randomabcdefgabcdefg###############################################################################abcdefg# Constants for the image input and output.abcdefg###############################################################################abcdefgabcdefg# Output folder for the images.abcdefgOUTPUT_DIR = 'output/'abcdefg# Style image to use.abcdefgSTYLE_IMAGE = 'images/guernica.jpg'abcdefg# Content image to use.abcdefgCONTENT_IMAGE = 'images/hongkong.jpg'abcdefg# Image dimensions constants. abcdefgIMAGE_WIDTH = 400abcdefgIMAGE_HEIGHT = 400abcdefgCOLOR_CHANNELS = 3abcdefgabcdefg###############################################################################abcdefg# Algorithm constantsabcdefg###############################################################################abcdefg# Noise ratio. Percentage of weight of the noise for intermixing with theabcdefg# content image.abcdefgNOISE_RATIO = 0.6abcdefgabcdefgVGG_MODEL = 'imagenet-vgg-verydeep-19.mat'abcdefgabcdefgMEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))abcdefgabcdefgdef build_model(input_img,IMAGE_WIDTH,IMAGE_HEIGHT,CHANNEL, layer_num):abcdefg  def conv_layer(layer_name, layer_input, W):abcdefg    conv = tf.nn.conv2d(layer_input, W, strides=[1, 1, 1, 1], padding='SAME')abcdefg    return convabcdefgabcdefg  def relu_layer(layer_name, layer_input, b):abcdefg    relu = tf.nn.relu(layer_input + b)abcdefg    return reluabcdefgabcdefg  def pool_layer(layer_name, layer_input):abcdefg    pool = tf.nn.avg_pool(layer_input, ksize=[1, 2, 2, 1], abcdefg      strides=[1, 2, 2, 1], padding='SAME')abcdefg      # pool = tf.nn.max_pool(layer_input, ksize=[1, 2, 2, 1], abcdefg      #   strides=[1, 2, 2, 1], padding='SAME')abcdefg    return poolabcdefgabcdefg  def get_weights(vgg_layers, i):abcdefg    weights = vgg_layers[i][0][0][2][0][0]abcdefg    W = tf.constant(weights)abcdefg    return Wabcdefgabcdefg  def get_bias(vgg_layers, i):abcdefg    bias = vgg_layers[i][0][0][2][0][1]abcdefg    b = tf.constant(np.reshape(bias, (bias.size)))abcdefg    return babcdefgabcdefg  net = {}abcdefg  abcdefg  vgg_rawnet     = scipy.io.loadmat(VGG_MODEL)abcdefg  vgg_layers     = vgg_rawnet['layers'][0]abcdefg  net['input']   = tf.Variable(np.asarray([input_img]), dtype=np.float32)abcdefg# np.zeros((1,IMAGE_WIDTH,IMAGE_HEIGHT,CHANNEL)abcdefg  if layer_num==1:abcdefg    net['conv1_1'] = conv_layer('conv1_1', net['input'], W=get_weights(vgg_layers, 0))abcdefg    net['relu1_1'] = relu_layer('relu1_1', net['conv1_1'], b=get_bias(vgg_layers, 0))abcdefgabcdefg    net['conv1_2'] = conv_layer('conv1_2', net['relu1_1'], W=get_weights(vgg_layers, 2))abcdefg    net['relu1_2'] = relu_layer('relu1_2', net['conv1_2'], b=get_bias(vgg_layers, 2))abcdefg    abcdefg    net['pool1']   = pool_layer('pool1', net['relu1_2'])abcdefgabcdefg    # if args.verbose: print('LAYER GROUP 2')  abcdefg    net['conv2_1'] = conv_layer('conv2_1', net['pool1'], W=get_weights(vgg_layers, 5))abcdefg    net['relu2_1'] = relu_layer('relu2_1', net['conv2_1'], b=get_bias(vgg_layers, 5))abcdefgabcdefg  if layer_num == 2:  abcdefg    net['conv2_1'] = conv_layer('conv2_1', net['input'], W=get_weights(vgg_layers, 5))abcdefg    net['relu2_1'] = relu_layer('relu2_1', net['conv2_1'], b=get_bias(vgg_layers, 5))abcdefg    net['conv2_2'] = conv_layer('conv2_2', net['relu2_1'], W=get_weights(vgg_layers, 7))abcdefg    net['relu2_2'] = relu_layer('relu2_2', net['conv2_2'], b=get_bias(vgg_layers, 7))abcdefg    abcdefg    net['pool2']   = pool_layer('pool2', net['relu2_2'])abcdefg    net['conv3_1'] = conv_layer('conv3_1', net['pool2'], W=get_weights(vgg_layers, 10))abcdefg    net['relu3_1'] = relu_layer('relu3_1', net['conv3_1'], b=get_bias(vgg_layers, 10))abcdefgabcdefg  if layer_num == 3:abcdefg    net['conv3_1'] = conv_layer('conv3_1', net['input'], W=get_weights(vgg_layers, 10))abcdefg    net['relu3_1'] = relu_layer('relu3_1', net['conv3_1'], b=get_bias(vgg_layers, 10))abcdefgabcdefg    net['conv3_2'] = conv_layer('conv3_2', net['relu3_1'], W=get_weights(vgg_layers, 12))abcdefg    net['relu3_2'] = relu_layer('relu3_2', net['conv3_2'], b=get_bias(vgg_layers, 12))abcdefgabcdefg    net['conv3_3'] = conv_layer('conv3_3', net['relu3_2'], W=get_weights(vgg_layers, 14))abcdefg    net['relu3_3'] = relu_layer('relu3_3', net['conv3_3'], b=get_bias(vgg_layers, 14))abcdefgabcdefg    net['conv3_4'] = conv_layer('conv3_4', net['relu3_3'], W=get_weights(vgg_layers, 16))abcdefg    net['relu3_4'] = relu_layer('relu3_4', net['conv3_4'], b=get_bias(vgg_layers, 16))abcdefgabcdefg    net['pool3']   = pool_layer('pool3', net['relu3_4'])abcdefgabcdefg    # if args.verbose: print('LAYER GROUP 4')abcdefg    net['conv4_1'] = conv_layer('conv4_1', net['pool3'], W=get_weights(vgg_layers, 19))abcdefg    net['relu4_1'] = relu_layer('relu4_1', net['conv4_1'], b=get_bias(vgg_layers, 19))abcdefgabcdefg  if layer_num == 4:abcdefg    net['conv4_1'] = conv_layer('conv4_1', net['input'], W=get_weights(vgg_layers, 19))abcdefg    net['relu4_1'] = relu_layer('relu4_1', net['conv4_1'], b=get_bias(vgg_layers, 19))abcdefgabcdefg    net['conv4_2'] = conv_layer('conv4_2', net['relu4_1'], W=get_weights(vgg_layers, 21))abcdefg    net['relu4_2'] = relu_layer('relu4_2', net['conv4_2'], b=get_bias(vgg_layers, 21))abcdefgabcdefg    net['conv4_3'] = conv_layer('conv4_3', net['relu4_2'], W=get_weights(vgg_layers, 23))abcdefg    net['relu4_3'] = relu_layer('relu4_3', net['conv4_3'], b=get_bias(vgg_layers, 23))abcdefgabcdefg    net['conv4_4'] = conv_layer('conv4_4', net['relu4_3'], W=get_weights(vgg_layers, 25))abcdefg    net['relu4_4'] = relu_layer('relu4_4', net['conv4_4'], b=get_bias(vgg_layers, 25))abcdefgabcdefg    net['pool4']   = pool_layer('pool4', net['relu4_4'])abcdefgabcdefg    # if args.verbose: print('LAYER GROUP 5')abcdefg    net['conv5_1'] = conv_layer('conv5_1', net['pool4'], W=get_weights(vgg_layers, 28))abcdefg    net['relu5_1'] = relu_layer('relu5_1', net['conv5_1'], b=get_bias(vgg_layers, 28))abcdefgabcdefg  if layer_num == 5:abcdefg    net['conv5_1'] = conv_layer('conv5_1', net['input'], W=get_weights(vgg_layers, 28))abcdefg    net['relu5_1'] = relu_layer('relu5_1', net['conv5_1'], b=get_bias(vgg_layers, 28))abcdefgabcdefg    net['conv5_2'] = conv_layer('conv5_2', net['relu5_1'], W=get_weights(vgg_layers, 30))abcdefg    net['relu5_2'] = relu_layer('relu5_2', net['conv5_2'], b=get_bias(vgg_layers, 30))abcdefgabcdefg    net['conv5_3'] = conv_layer('conv5_3', net['relu5_2'], W=get_weights(vgg_layers, 32))abcdefg    net['relu5_3'] = relu_layer('relu5_3', net['conv5_3'], b=get_bias(vgg_layers, 32))abcdefgabcdefg    net['conv5_4'] = conv_layer('conv5_4', net['relu5_3'], W=get_weights(vgg_layers, 34))abcdefg    net['relu5_4'] = relu_layer('relu5_4', net['conv5_4'], b=get_bias(vgg_layers, 34))abcdefgabcdefg    net['pool5']   = pool_layer('pool5', net['relu5_4'])abcdefgabcdefg  return netabcdefgabcdefgabcdefgabcdefgabcdefgdef createImage(tensor):abcdefg    newImage = np.zeros((len(tensor[0]),len(tensor[0][0]),3))abcdefg    for z in range(len(tensor[0][0][0])):abcdefg        for y in range(len(tensor[0])):abcdefg          for x in range(len(tensor[0][y])):abcdefg            newImage[y][x][0] = tensor[0][y][x][z]abcdefg            newImage[y][x][1] = tensor[0][y][x][z]abcdefg            newImage[y][x][2] = tensor[0][y][x][z]abcdefg        newImage = np.asarray(newImage).astype('float64')abcdefg        newImage += 127.0#MEAN_VALUES[0]abcdefg        newImage = newImage[:, :, ::-1]abcdefg        newImage = np.clip(newImage, 0, 255).astype('uint8')abcdefg    print(newImage.shape)abcdefg    return newImageabcdefgabcdefgabcdefgdef minimize_with_lbfgs(sess, net, optimizer, init_img, goal_img):abcdefg  init_op = tf.global_variables_initializer()abcdefg  sess.run(init_op)abcdefg  sess.run(net['input'].assign(init_img))abcdefg  # sess.run(net['y_'].assign(goal_img))abcdefg  optimizer.minimize(sess)abcdefgabcdefgdef minimize_with_adam(sess, net, optimizer, init_img, goal_img, loss, max_iterations, check_layer, output_layer, print_iterations):abcdefg  train_op = optimizer.minimize(loss)abcdefg  init_op = tf.global_variables_initializer()abcdefg  sess.run(init_op)abcdefgabcdefg  iterations = 0abcdefg  while (iterations < max_iterations):abcdefg    sess.run(train_op)abcdefg    if iterations % print_iterations==0:abcdefg      curr_loss = loss.eval()abcdefg      print("At iterate {}\tf=  {:.5E}".format(iterations, curr_loss))abcdefg      # cv2.imwrite("./output/"+str(iterations)+"_input.jpg",createImage(sess.run(net[output_layer])))abcdefg      # cv2.imwrite("./output/"+str(iterations)+"_relu.jpg",createImage(sess.run(net[check_layer])))abcdefgabcdefg    iterations += 1abcdefgabcdefgabcdefgdef getLoss(sess, vggModel, layer, generate_image, goal_image):abcdefgabcdefg    sess.run(vggModel['input'].assign(generate_image))abcdefgabcdefg    sub = tf.subtract(vggModel[layer],vggModel['y_'])abcdefg    abso= tf.norm(sub)abcdefg    return tf.pow(abso,2)abcdefgabcdefgabcdefgdef get_optimizer(loss, select_optimizer, learning_rate, max_iterations, print_iterations):abcdefg  if select_optimizer == 'lbfgs':abcdefg    optimizer = tf.contrib.opt.ScipyOptimizerInterface(abcdefg      loss, method='L-BFGS-B',abcdefg      options={'maxiter': max_iterationsabcdefg                  })abcdefg  elif select_optimizer == 'adam':abcdefg    optimizer = tf.train.AdamOptimizer(learning_rate)abcdefg  return optimizerabcdefgabcdefgabcdefgabcdefgdef newDeconv(sess, goal_img, select_optimizer, max_iterations, check_layer, output_layer, layer_num):abcdefg    # vggModel['y_'] = tf.Variable(tf.constant(goal_img))abcdefg    noise = generateNoiseImage(int(len(goal_img[0])*2),int(len(goal_img[0][0])*2),128)abcdefg    noise = np.asarray(noise,dtype=np.float32)abcdefg    noise -= 127.0abcdefg    init_img = np.asarray([noise],dtype=np.float32)abcdefgabcdefg    goal_img -=127.0abcdefg    goal_img = np.asarray([goal_img],dtype=np.float32)abcdefgabcdefgabcdefg    # noise -= 127.0#MEAN_VALUES[0]abcdefg    vggModel = build_model(noise,int(len(goal_img[0])*2),int(len(goal_img[0][0])*2),128,layer_num)abcdefg    vggModel['y_'] = tf.constant(goal_img)abcdefgabcdefg    L_total=getLoss(sess, vggModel, check_layer, init_img, goal_img)abcdefg    # L_total = sum_total_variation_losses(sess, vggModel, init_img)abcdefg    optimizer=get_optimizer(L_total,select_optimizer, 1e-1, max_iterations,1000)abcdefg    if select_optimizer == 'adam':abcdefg        minimize_with_adam(sess, vggModel, optimizer, init_img, goal_img, L_total,max_iterations,1000)abcdefg    elif select_optimizer == 'lbfgs':abcdefg        minimize_with_lbfgs(sess, vggModel, optimizer, init_img, goal_img)abcdefgabcdefg    return sess.run(vggModel[output_layer])abcdefg    # output_img = sess.run(vggModel[check_layer])abcdefg    # in_img = sess.run(vggModel[output_layer])abcdefgabcdefg    # print(output_img.shape)abcdefg    # output_img = createImage(output_img)abcdefg    # print(output_img.shape)abcdefg    # output_img = createImage(output_img)# + MEAN_VALUESabcdefg    # output_img = np.clip(output_img,0,255).astype('uint8')abcdefg    # cv2.imshow("L4",output_img)abcdefg    # cv2.waitKey(0)abcdefg    # cv2.imshow("L3_2",createImage(in_img))abcdefg    # cv2.waitKey(0)abcdefg    # cv2.imshow("input",createImage(sess.run(vggModel['input'])))abcdefg    # cv2.waitKey(0)abcdefgabcdefgdef generateNoiseImage(height, width, channel):abcdefg    randomByteArray = bytearray(os.urandom(height*width*channel)) #画素数文の乱数発生abcdefg    return np.asarray(randomByteArray).reshape((height, width, channel))abcdefgabcdefgdef getMono(img):abcdefg    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)abcdefgabcdefgabcdefgabcdefgabcdefgsess = tf.InteractiveSession()abcdefgtf.global_variables_initializer().run()abcdefg# model = load_vgg_model(VGG_MODEL,len(PhiAB[0]),len(PhiAB[0][0]),512)abcdefgabcdefg# img = cv2.imread('avater.jpg')abcdefg# img = np.asarray(img).astype('float64')abcdefgabcdefg# img -= MEAN_VALUES[0]abcdefg# img = img[:, :, ::-1].astype('float64')abcdefgabcdefgabcdefg# # img = img.transpose((2, 0, 1))abcdefg# img = np.expand_dims(img, axis=0)abcdefgabcdefg# sess.run(model['input'].assign(np.asarray(img)))abcdefg# A=[]abcdefg# A.append(createImage(sess.run(model['conv1_1'])))abcdefg# A.append(createImage(sess.run(model['conv2_1'])))abcdefg# A.append(createImage(sess.run(model['conv3_1'])))abcdefg# A.append(createImage(sess.run(model['conv4_1'])))abcdefg# A.append(createImage(sess.run(model['conv5_1'])))abcdefgabcdefg# PhiAB =getPhi_Random(A[5-1])abcdefg# noise = generateNoiseImage(IMAGE_HEIGHT,IMAGE_WIDTH,3)abcdefg# cv2.imshow("",noise)abcdefg# cv2.waitKey(0)abcdefg# PhiAB = getMono(PhiAB)abcdefg# noise = getMono(noise)abcdefg# cv2.imshow("",warp(A[5-1],PhiAB))abcdefg# cv2.waitKey(0)abcdefg# sess, generate_image, goal_image, channel, select_optimizer, max_iterationsabcdefg# deconv(sess, np.asarray([noise],dtype=np.float32), np.asarray([PhiAB],dtype=np.float32),3,'adam', 20000)abcdefg# deconv(noise, PhiAB, 3, 20000)abcdefgPhiAB = cv2.imread("L4.jpg",cv2.IMREAD_GRAYSCALE)abcdefgabcdefggoal = np.zeros((len(PhiAB),len(PhiAB[0]),512))abcdefgfor y in range(len(PhiAB)):abcdefg    for x in range(len(PhiAB[y])):abcdefg        for z in range(512):abcdefg            goal[y][x][z] = PhiAB[y][x]abcdefgabcdefg# goal = np.asarray(goal,dtype='float32')abcdefgabcdefgabcdefgabcdefgabcdefgabcdefgabcdefg# graph = TrueDeconvGrapf(np.asarray([noise],dtype=np.float32), np.asarray([PhiAB],dtype=np.float32), 3)abcdefgtf.global_variables_initializer().run()abcdefgabcdefgabcdefgimg = newDeconv(sess,  goal,'adam', 200001,3)abcdefgsess.close()abcdefg
